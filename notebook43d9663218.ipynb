{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9997953,"sourceType":"datasetVersion","datasetId":6153662}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n%pip install -U transformers \n%pip install -U datasets \n%pip install -U accelerate \n%pip install -U peft \n%pip install -U trl \n%pip install -U bitsandbytes \n%pip install -U wandb","metadata":{"_uuid":"93fc837f-b8f6-4de7-9511-01002ecdfb95","_cell_guid":"8cd30fbd-6fd3-4cbb-96cb-a3a17afb1691","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-24T08:19:17.346901Z","iopub.execute_input":"2024-11-24T08:19:17.347515Z","iopub.status.idle":"2024-11-24T08:20:44.072461Z","shell.execute_reply.started":"2024-11-24T08:19:17.347477Z","shell.execute_reply":"2024-11-24T08:20:44.071364Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    TrainingArguments,\n    pipeline,\n    logging,\n)\nfrom peft import (\n    LoraConfig,\n    PeftModel,\n    prepare_model_for_kbit_training,\n    get_peft_model,\n)\nimport os, torch, wandb\nfrom datasets import load_dataset\nfrom trl import SFTTrainer, setup_chat_format","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T08:21:01.422962Z","iopub.execute_input":"2024-11-24T08:21:01.423688Z","iopub.status.idle":"2024-11-24T08:21:19.190218Z","shell.execute_reply.started":"2024-11-24T08:21:01.423653Z","shell.execute_reply":"2024-11-24T08:21:19.189563Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\n\nlogin(token = \"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\")\n\n\n\nwandb.login(key=\"94f165f80ac98c766ee93ad22e84ead39d2593b2\")\nrun = wandb.init(\n    project='llama_interview_3Bins', \n    job_type=\"training\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T08:21:58.749851Z","iopub.execute_input":"2024-11-24T08:21:58.751103Z","iopub.status.idle":"2024-11-24T08:22:02.425125Z","shell.execute_reply.started":"2024-11-24T08:21:58.751066Z","shell.execute_reply":"2024-11-24T08:22:02.424326Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch_dtype = torch.float16\nattn_implementation = \"eager\"\n\n# quantization \nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch_dtype,\n    bnb_4bit_use_double_quant=True,\n)\nmodel_name = \"meta-llama/Llama-3.2-3B-Instruct\"\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n    attn_implementation=attn_implementation\n)\n\nprint(\"done !\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T08:22:12.782064Z","iopub.execute_input":"2024-11-24T08:22:12.782423Z","iopub.status.idle":"2024-11-24T08:24:56.490104Z","shell.execute_reply.started":"2024-11-24T08:22:12.782391Z","shell.execute_reply":"2024-11-24T08:24:56.489228Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\")\nmodel, tokenizer = setup_chat_format(model, tokenizer)\nprint(\"done !\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T08:34:16.517505Z","iopub.execute_input":"2024-11-24T08:34:16.518307Z","iopub.status.idle":"2024-11-24T08:34:17.187562Z","shell.execute_reply.started":"2024-11-24T08:34:16.518249Z","shell.execute_reply":"2024-11-24T08:34:17.186453Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# LoRA config\npeft_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=['up_proj', 'down_proj', 'gate_proj', 'k_proj', 'q_proj', 'v_proj', 'o_proj']\n)\nmodel = get_peft_model(model, peft_config)\nprint(\"done !\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T08:34:50.244301Z","iopub.execute_input":"2024-11-24T08:34:50.244648Z","iopub.status.idle":"2024-11-24T08:34:50.677501Z","shell.execute_reply.started":"2024-11-24T08:34:50.244620Z","shell.execute_reply":"2024-11-24T08:34:50.676122Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Importing the dataset\ndataset = load_dataset(\"json\", data_files=\"/kaggle/input/qa-datasetttt/qa_dataset.json\")\n\n\nprint(dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T08:40:15.659770Z","iopub.execute_input":"2024-11-24T08:40:15.660084Z","iopub.status.idle":"2024-11-24T08:40:16.431028Z","shell.execute_reply.started":"2024-11-24T08:40:15.660059Z","shell.execute_reply":"2024-11-24T08:40:16.430002Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the function to format the chat template\ndef format_chat_template(row):\n    row_json = [\n        {\"role\": \"user\", \"content\": row[\"question\"]},\n        {\"role\": \"assistant\", \"content\": row[\"answer\"]}\n    ]\n    row[\"text\"] = tokenizer.apply_chat_template(row_json, tokenize=False)  # Assumes `tokenizer` supports `apply_chat_template`\n    return row\n\n# Apply the function using `map`\ndataset = dataset.map(\n    format_chat_template,\n    num_proc=4,  # Number of processes for parallelization\n)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T08:44:00.376155Z","iopub.execute_input":"2024-11-24T08:44:00.376543Z","iopub.status.idle":"2024-11-24T08:44:00.999025Z","shell.execute_reply.started":"2024-11-24T08:44:00.376510Z","shell.execute_reply":"2024-11-24T08:44:00.998269Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set the pad_token to eos_token\ntokenizer.pad_token = tokenizer.eos_token\n\n# Now you can tokenize with padding\ntokenized_dataset = dataset.map(\n    lambda x: tokenizer(x['question'], x['answer'], truncation=True, padding=\"max_length\", max_length=512),\n    batched=True\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T08:54:53.176482Z","iopub.execute_input":"2024-11-24T08:54:53.177244Z","iopub.status.idle":"2024-11-24T08:54:53.400059Z","shell.execute_reply.started":"2024-11-24T08:54:53.177210Z","shell.execute_reply":"2024-11-24T08:54:53.399244Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if \"train\" in dataset:\n    dataset = dataset[\"train\"]\n\n# Split the dataset into train and test\nsplit_dataset = dataset.train_test_split(test_size=0.1, seed=42)\n\n# Access train and test sets\ntrain_dataset = split_dataset[\"train\"]\ntest_dataset = split_dataset[\"test\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T08:54:58.279136Z","iopub.execute_input":"2024-11-24T08:54:58.279886Z","iopub.status.idle":"2024-11-24T08:54:58.293773Z","shell.execute_reply.started":"2024-11-24T08:54:58.279851Z","shell.execute_reply":"2024-11-24T08:54:58.292880Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"training_arguments = TrainingArguments(\n    output_dir=\"finetuned_llama_interview_iyed\",\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size=1,\n    gradient_accumulation_steps=2,\n    optim=\"paged_adamw_32bit\",\n    num_train_epochs=10,\n    evaluation_strategy=\"steps\",\n    eval_steps=0.2,\n    logging_steps=1,\n    warmup_steps=10, #will overfitt but fine iwant it to \n    logging_strategy=\"steps\",\n    learning_rate=2e-4,\n    fp16=False,\n    bf16=False,\n    group_by_length=True,\n    report_to=\"wandb\"\n)\n\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=train_dataset,\n    eval_dataset=test_dataset,\n    peft_config=peft_config,\n    max_seq_length=512,\n    dataset_text_field=\"text\",\n    tokenizer=tokenizer,\n    args=training_arguments,\n    packing= False,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T09:13:20.674244Z","iopub.execute_input":"2024-11-24T09:13:20.674903Z","iopub.status.idle":"2024-11-24T09:13:21.115117Z","shell.execute_reply.started":"2024-11-24T09:13:20.674869Z","shell.execute_reply":"2024-11-24T09:13:21.114240Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T09:13:23.784796Z","iopub.execute_input":"2024-11-24T09:13:23.785342Z","iopub.status.idle":"2024-11-24T09:18:25.362403Z","shell.execute_reply.started":"2024-11-24T09:13:23.785301Z","shell.execute_reply":"2024-11-24T09:18:25.361624Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"messages = [\n    {\n        \"role\": \"user\",\n        \"content\": \"what's your name  ?\"\n    }\n]\n\nprompt = tokenizer.apply_chat_template(messages, tokenize=False, \n                                       add_generation_prompt=True)\n\ninputs = tokenizer(prompt, return_tensors='pt', padding=True, \n                   truncation=True, max_length=512).to(\"cuda\")\n\n\noutputs = model.generate(**inputs, max_length=150, num_return_sequences=1)#, num_beams=10, early_stopping=False, repetition_penalty=2.2)\n\ntext = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\nprint(text.split(\"assistant\")[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T09:50:39.772117Z","iopub.execute_input":"2024-11-24T09:50:39.772756Z","iopub.status.idle":"2024-11-24T09:50:45.726539Z","shell.execute_reply.started":"2024-11-24T09:50:39.772721Z","shell.execute_reply":"2024-11-24T09:50:45.725697Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.model.save_pretrained(\"llama_3Bins_interview\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T09:27:53.851071Z","iopub.execute_input":"2024-11-24T09:27:53.851924Z","iopub.status.idle":"2024-11-24T09:27:54.176596Z","shell.execute_reply.started":"2024-11-24T09:27:53.851888Z","shell.execute_reply":"2024-11-24T09:27:54.175729Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import login\nlogin(token=\"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\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T09:44:51.226933Z","iopub.execute_input":"2024-11-24T09:44:51.227343Z","iopub.status.idle":"2024-11-24T09:44:51.465905Z","shell.execute_reply.started":"2024-11-24T09:44:51.227304Z","shell.execute_reply":"2024-11-24T09:44:51.465149Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.push_to_hub(\"iy3d1243/finetuned-llama-interview-model\")\ntokenizer.push_to_hub(\"iy3d1243/finetuned-llama-interview-model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T09:44:55.925768Z","iopub.execute_input":"2024-11-24T09:44:55.926408Z","iopub.status.idle":"2024-11-24T09:45:11.583680Z","shell.execute_reply.started":"2024-11-24T09:44:55.926373Z","shell.execute_reply":"2024-11-24T09:45:11.582947Z"}},"outputs":[],"execution_count":null}]}